1. What is node.js
    runtime environment for js
    v8 engine
    async,event driven architecture
    single threaded non blocking i/o model
    used in both clide side and server side programing

2. Advantages
    Async and non blocking
    scalability- can handle high volume traffics
    npm
    v8 engine known for fast performance

3. Disadvantages
    not a good choice for cpu intense task
    node has a minimum standard library, which often necessitates the use of third-party modules from npm
    chances high for memory leak

4. V8 engine
    Node.js uses v8 engine to execute js outside browser
    It is a js Engine built by google
    It is known for its fast execution and performance
    V8 uses just in time compilation tectnique
    compile js directly into machine code at the time of execution
    V8 includes a garbage collector to manange memory allocation and deallocation

5. How does node.js works
    First Client send request to web server.
    Request will be added in Event Queue
    Event Loop will check if there is any request in Event Queue if there is any then it will check the request is blocking or non-blocking
    If request is non-blocking then it will immediately process and send the response to the user.
    If Request is Blocking Operation we will go to Thread Pool
    Blocking Operation will send request to Thread pool . thread pool will check if there is any thread available. As there are limited thread in thread pool.
    If thread is free it will send request to thread and when request is performed it will send back the result

    Order of execution
        All functions that are currently in the call stack get executed and then they get popped off the call-stack.
        When the call stack is empty, all queued-up micro-tasks are popped onto the call-stack one by one and get executed, and then they get popped off the call-stack.
        When both the call-stack and micro-task queue are empty, all queued-up macro-tasks are popped onto the call-stack one by one and get executed, and then they get popped off the call-stack.

6. concurrency vs parallelism
    concurrency means dealing with multiple tasks at the same time but not necessarily executing them simultaneously.This can involve context switching, where the CPU switches between different tasks, giving the illusion that they are running at the same time.

    This can involve context switching, where the CPU switches between different tasks, giving the illusion that they are running at the same time.
    mechanisms to achieve parallelism:

        Worker Threads: Node.js provides a worker_threads module to run JavaScript in parallel on multiple threads.
        Child Processes: You can use the child_process module to fork separate processes that run concurrently.
        Cluster Module: This allows you to create a cluster of Node.js processes that can share server ports.

7. REPL and CLi
    Read EvaL Print loop and Command Line Interface
    REPL is an interactive shell for real-time code execution and debugging, providing immediate feedback and an environment for exploration.
    CLI is a command-line interface for running Node.js scripts, automating tasks, and managing packages, suitable for executing and reusing scripts in a more structured manner.

    REPL is best for interactive and immediate code execution, while CLI is geared towards running and managing scripts and packages from the command line

8. Node Module System
    The ECMAScript Module (ESM) system and CommonJS are two different module systems used in JavaScript and Node.js for organizing and managing code
    commonjs
        Uses `require` to import modules.
        Uses `module.exports` or `exports` to export modules.
    ESM
        Uses `import` to import modules.
        Uses `export` to export modules.

9. NPM and NPX
      `NPM` is a package manager that installs, deletes, and updates JavaScript packages, 
      `NPX` is a package executer, used to run JavaScript packages without installing them

10. Globals
    In Node.js, several global objects, functions, and variables are available in all modules. These globals do not require an import statement to use them.Two of the most important global objects are process and module.
    * process
        The `process` object provides information and control over the current Node.js process. It is an instance of EventEmitter and includes a wide variety of methods and properties.
            * process.env
            * process.argv
            * process.cwd
            * process.exit
    * module
        The `module` object represents the current module and provides information about it. It allows for managing the exports of the module and accessing the module's metadata.

    Global Variables: __dirname, __filename

11. Modules
    *  module is a piece of reusable JavaScript code that encapsulate functionalities.
    * It can be imported into other modules using require()
    * and export it using mosule.exports or exports
    * Each module have its own scope
    * 3 Types
        + Built-in/Core modules -http,fs,crypto,path,url
        + Local
        + 3rd Party - express.js,mongoose,passport.js,multer etc

12. Package.json vs Package-lock.json
    package.json contains metadata about the project like name,version, dependencies etc
    
    package-lock.json is generated by npm .It provide a detailed version specific representation of the dependency tree
    It lock the versions of dependancy used inthe project

13. Stream
    Streams in NodeJS are a way to move data from a source to a destination in a bit-by-bit (or let’s say, in chunks), to avoid any Out-of-Memory Errors.

     They are data-handling method and are used to read or write input into output sequentially.

     What makes streams unique, is that instead of a program reading a file into memory all at once like in the traditional way, streams read chunks of data piece by piece, processing its content without keeping it all in memory

     Advantages:
        Memory efficiency: you don’t need to load large amounts of data in memory before you are able to process it

        Time efficiency: it takes significantly less time to start processing data as soon as you have it, rather than having to wait with processing until the entire payload has been transmitted

    There are 4 types of streams in Node.js:
        
        * Writable: streams to which we can write data. For example, fs.createWriteStream() lets us write data to a file using streams.
        * Readable: streams from which data can be read. For example: fs.createReadStream() lets us read the contents of a file.
        * Duplex: streams that are both Readable and Writable. For example, net.Socket
        * Transform: streams that can modify or transform the data as it is written and read. For example, in the instance of      file-compression, you can write compressed data and read decompressed data to and from a file.

        Transform streams are special kind of duplex streams. Instead of simply passing the data from the read stream to the write stream, transform streams change the data. 

14. Cron jobs
        Cron jobs are ideal for automating repetitive tasks that need to run at regular intervals. This can include:

        Sending out regular email newsletters.
        Running database backups.
        Cleaning up temporary files.
        Fetching data from an API and storing it in a database.

        Once a cron job is set up, it runs automatically according to the specified schedule without the need for manual intervention. This ensures tasks are executed consistently and on time.

15. CORS
    Cross Orgin Resource Sharing is a security mechanism implemented by web browsers to restrict access of resources from a different orgin.
    It is designed to prevent attacks such as:XXS (Cross site scripting )and CSRF (Cross site request forgery)
    It allows servers to specify which domains can access its resources.
    When client makes request to server ,the server in its reponse give a header called access control allow orgin
    This header specifies which domains are allowed to access the resources
    If the requesting domain is not in the list ,browser will block the request.

    `preflight Request`
    Before making the actual Http request ,web browsers first make a preflight options request to check whether the http request is safe to sent.
    A preflight request is sent:
        1. When http method is something other than simple get,post or head
        2.When the request includes credentials (e.g., cookies, HTTP authentication).
    Steps in a Preflight Request
        Preflight Request (OPTIONS): The browser sends an OPTIONS request to the server to determine if the actual request is safe to send.
        Server Response: The server responds with the appropriate CORS headers indicating whether the actual request is allowed.
        Actual Request: If the server allows the preflight request, the browser then sends the actual request.

    Access-Control-Allow-Origin: Specifies which origin can access the resource.
    Access-Control-Allow-Methods: Specifies which methods are allowed when accessing the resource.

16. Cluster
        Node.js follows the single threaded event loop based architecture. 
        Even if the computer has more than one CPU core, Node.js does not use all of them by default. 
        It only uses one CPU core for the main thread that handles the event loop.
        To handle such a heavy load, we need to launch a cluster of such Node.js processes and hence make use of multiple cores.

        Node.js comes bundled up with a cluster module.
        The cluster module permits the creation of child processes, that are copies of your program operating concurrently on the same server port.
        Each child process possesses an event loop, V8 instance and memory. 
        There is a parent process routing traffic to these child processes. 
        To communicate with the parent processes, the child processes employ interprocess communication.

        Hence while using the cluster module, you will have four copies of your program in case of a 4-core machine.
        This will allow you to handle four times the normal traffic at the same speed.
        Therefore clustering is capable of giving a performance boost to your Node.js application.

        Scalability is needed when an application’s clients grow
        Clustering acts as a load-balancing and parallel processing service.

17. When an event (such as a client request) occurs, it is placed into the event queue. Node.js uses an event loop to manage and process these events. The event loop continuously checks the event queue and processes each event in a non-blocking manner. Here's how it works:

        1. **Non-blocking Code**:
            - For non-blocking I/O operations, Node.js registers the callbacks and immediately continues processing the next event. These non-blocking operations are handled by libuv, which uses an internal thread pool to perform I/O operations asynchronously.

        2. **Blocking Code**:
            - Blocking code can prevent the event loop from processing further events. Therefore, it is important to avoid long-running synchronous code in Node.js applications to maintain responsiveness.

        3. **Libuv and Thread Pool**:
            - Libuv manages the event loop and thread pool. For I/O operations (like file reading), libuv delegates the task to the thread pool, allowing the main thread to remain free to handle other events.

        4. **Microtasks and Macrotasks**:
            - Tasks are divided into microtasks and macrotasks:
                - **Microtasks** (e.g., `process.nextTick`, Promises) have higher priority and are executed before the next rendering frame.
                - **Macrotasks** (e.g., I/O callbacks, `setTimeout`, `setInterval`, `setImmediate`) are executed in specific phases of the event loop.

        5. **Callback Execution**:
            - When an asynchronous operation completes, its callback is placed in the corresponding queue. The event loop phases (timers, I/O callbacks, etc.) determine when these callbacks are executed.
            - The call stack executes the actual JavaScript code. If the call stack is empty, the event loop picks the next callback from the appropriate queue and pushes it onto the call stack for execution.

        In summary, the event loop checks the event queue, processes non-blocking operations immediately, delegates I/O tasks to libuv's thread pool, and uses a prioritized task scheduling system to manage and execute callbacks efficiently.
 
18. Ports are just endpoints of communication, simply put a location where a user or request will arrive.Ports
     allow us to identify where our application connection exists. We mainly see it as http://localhost:XXXX. where the exes are numbers that characterize the port. Localhost simply stands for our local machine’s ip adress to be recognized by the http protocol, and so the port number will be the location entry point for our server or app’s server.

19. The static method of express allows us to serve all the static files of our application, that is to say, all HTML, CSS, and JS files that  will  comprise the front end visuals on the browser.By placing the express.static() in app.use, we let our server know that we will be rendering that index.html file and implementing all those static CSS and JS files related to it.

    app.use(express.static('public'));

20. HTTP
    Hyper Text Transfer Protocol is used to fetch html documents or transfer data between client and server in a web.
    A more secure version, HTTPS, can be used in order to encrypt information sent between the client and server.
     This encryption is done with Transport Layer Security (or TLS, formerly SSL).

21. How does Http work

    Http operates as a request-response protocol between a client and a server.
    Request-Response Cycle:
        * Client initiates a request to the server
        * Client establishes a TCP connection with the server.
        * The request include:
            1.Request Line:contains  http method,resource path, and http version
            2.Header provide metadatas about the request such as host name,user agent ,accepted response formats
            3.Body: Contains data sent to the server,used in methods like POST and PUT
        *Server recieves and process the request,perforn necessary operations and prepare a response.
        * Server sends the response back to the client.
        *The response include:
            Status Line: HTTP version, ststus codeand status message
            Header: mdata such as content type and length
            Body : Request resource data
        * Client receives and process the response
        *TCP connection is close

    HTTP headers consist of key-value pairs that provide metadata about the request or response. 
    There are numerous HTTP headers, but some commonly used categories include:

        General Headers: These apply to both requests and responses, providing information like the HTTP version, connection type, and host name. (e.g., Connection, Host)
        Request Headers: Sent by the client, they specify details about the requested resource, browser capabilities, and any authentication. (e.g., User-Agent, Authorization, Content-Type)
        Response Headers: Sent by the server, they provide the status code, content type, and other relevant details about the response. (e.g., Content-Type, Status Code, Cache-Control)

22. HTTP Methods
    * GET -Retrieves data from the server
    * POST -Send data to the server to create new resource
    * Put Update an existing resource on the server
    * Delete Remove a resource from the server
    * Head Retrieve the header for a resource without body
    * OPTIONS Retrieve the HTTP methods supported by the server.
        provide a way to check the communication options available for a specific resource or server. It plays a crucial role in CORS by facilitating preflight requests and helps in discovering supported HTTP methods for resources, ensuring proper communication and enhancing security in web applications.
    * PATCH Apply partial modifications to a resource

   Idempotent Methods: GET, HEAD, PUT, DELETE, OPTIONS.
     Non-Idempotent Methods: POST

23. HTTP Status Code
    1XX :Request Received ,continuing process
    2XX :Request successfully received
        200 OK : Request was successful
        201 Created: The request was successful and a new resource was created
    3XX: Further action needs to be taken to complete the requets
    4XX: Clent Error
        400 Bad Request
        401 Unauthorized
        404 Not Found
    5XX Server Error

24. The Web Storage API provides a way for web applications to store data locally within the user's browser. This is a significant improvement over cookies, which were previously the main method for client-side data storage. Here's a breakdown of the key points:

Benefits over Cookies:

Storage Limits: Web Storage offers a much larger storage capacity (typically at least 5MB) compared to cookies, allowing you to store more data without affecting performance.
Security: Data stored using Web Storage is more secure than cookies because it's not sent with every request to the server.
Performance: Since data isn't sent back and forth with the server, Web Storage can improve website performance.
Types of Storage:

The Web Storage API offers two mechanisms for storing data:

localStorage: This object stores data with no expiration date. Even if the browser is closed and reopened, the data persists until it's manually cleared.
sessionStorage: This object functions similarly to localStorage but with a shorter lifespan. Data stored in sessionStorage is only available for the current session (until the browser tab or window is closed).
How it Works:

Use Cases:

Web Storage can be used for various purposes, including:

Persisting user preferences (e.g., language, theme) across sessions.
Storing user authentication tokens.
Caching data to improve website responsiveness.
Maintaining application state during page refreshes

25. In the context of HTTP, "safe methods" are those methods that do not modify the state of the server; they are intended only for retrieving data. These methods can be called without any risk of changing the server's resources, making them idempotent and safe for read-only operations.
eg .get,head,options

26. writeHead vs SetHead

    Both writeHead and setHeader are methods used for setting HTTP headers in Node.js, but they differ in their functionality and timing:
    writeHead: Sends the HTTP response header information immediately to the client.
                After calling writeHead, you cannot set any further headers for that response.
                deal for scenarios where you have all the necessary header information upfront and want to send the response immediately.
    setHead:Sets a specific header for the upcoming HTTP response.
             can call setHeader multiple times to set different headers before sending the response.
            Use Case: Useful when you need to build the response headers incrementally or want to conditionally set headers based on certain logic.

27. MIME type
    A MIME type, also known as a media type, is a standardized way to identify the format of a file or the nature of the content being transmitted on the web.A MIME type consists of two parts separated by a slash (/):main type and sub type
    eg: text/html

28. Route Params
    They are used to create dynamic URL.They act like placeholder in URL that capture specfic value given by the user.
                eg:
                app.get('/users/:id', (req, res) => {
                // Handle request for a specific user with ID
                });
    The captured values of route parameters are accessible within your route handler function through the req.params object.

    Flexibility: Route parameters allow you to create more flexible and user-friendly URLs that clearly communicate the resource being requested.
    Organization: They help organize your routes by separating dynamic parts from static parts, making your code cleaner and easier to maintain.
    Reusability: Route handler functions can be designed to work with different captured values, promoting code reusability.

29. Query Param
        Query parameters are used to convey additional information to the server, allowing for more dynamic and flexible URLs.Query parameters reside in the query string, which is the part of the URL that follows a question mark (?). Within the query string, parameters are formatted as key-value pairs separated by ampersands (&).

        https://www.example.com/search?q=web+development&sort=newest

30. Body parser middleware , parse the request body into a JavaScript object or string that your route handlers can easily access and manipulate.
31. Morgan middleware is a popular tool for logging information about HTTP requests made to your application. It serves as a request logger, providing valuable insights into how your application is being used and helping with debugging and monitoring.

32. Cluster
    In node cluster module helps to create cluster of worker processes(node instance) that shares a single server ports.This enables to use multiple cpu cores to handle concurrent requests more efficiently and improve scalability
    Node.js is inherently single threaded but cluster helps to implement multi processing by creating multiple worker processes that use multple cpu cores
    Each worker process in a cluster is a separate instance of your Node.js application that can handle incoming requests independently. The master process manages the worker processes, spawning new ones when needed and handling communication between them

33. Worker Threads

   the worker_threads module allows you to create multiple threads within a single Node.js process. These threads can execute JavaScript code concurrently, enabling the handling of CPU-bound tasks more efficiently compared to the single-threaded event loop.
    Thread vs. Process: Threads are lightweight units of execution within a single process, while processes are separate instances of an application with their own memory space.
    Use Cases:
    CPU-intensive tasks that would block the event loop in the main thread, such as complex calculations or image processing.
    Offloading tasks that don't heavily rely on I/O operations to worker threads for improved performance.
    Key Differences (Cluster vs. Worker Threads):

    Feature	Cluster	Worker Threads
    Process Model	Multi-processing (multiple Node.js processes)	Multi-threading (multiple threads within a single Node.js process)
    Communication	Inter-process communication (IPC)	Message passing between threads
    Memory Sharing	Separate memory spaces for each worker	Shared memory space between threads
    Use Cases	I/O-bound tasks (more efficient for scaling)	CPU-bound tasks (more efficient for calculations)

    drive_spreadsheet
    Export to Sheets
    Choosing Between Cluster and Worker Threads:

    If your application is I/O-bound (e.g., network requests, database interactions), then cluster might be a better choice for scaling by distributing workload across multiple CPU cores.
    If your application involves CPU-intensive tasks that would block the event loop, then worker_threads might be a better option for improved performance by offloading those tasks to separate threads.


    Worker Threads Module (worker_threads)

    Concept: Worker threads introduce multi-threading within a single Node.js process. You can create multiple threads that execute JavaScript code concurrently, sharing the same memory space with the main thread.
    Communication: Threads communicate with each other by passing messages through the postMessage API.
    Memory Sharing: Threads share the memory space of the main Node.js process, allowing for faster data exchange compared to IPC in cluster.
    Use Cases: Worker threads are a good choice for CPU-bound tasks that would block the event loop in the main thread. These tasks might involve complex calculations, image processing, or any operation that heavily utilizes the CPU

34. Child processes are a powerful tool in Node.js that allow you to extend your application's functionality by creating new processes that run concurrently with the main process. These child processes can be used for various purposes, such as executing long-running tasks, running shell commands, or interacting with external programs.

Key Concepts:

Creation: The child_process module provides several methods for creating child processes:
fork: Creates a new Node.js process as a child, sharing the same JavaScript environment as the parent process. Ideal for creating worker processes in a cluster environment due to efficiency and some level of message passing.
exec: Executes a shell command and buffers the entire output of the command into a string. Useful for simple commands where you need the complete output at once.
execFile: Similar to exec but avoids buffering the entire output, making it suitable for handling larger outputs from commands.
spawn: Offers the most flexibility for interacting with the child process. You specify the executable (shell command or path to a Node.js script) and receive streams for both standard input (stdin) and standard output (stdout) of the child process.
Communication Channels:

The communication capabilities between parent and child processes depend on the creation method:

fork: Enables some level of message passing between parent and child using techniques like process.send() in the child and worker.on('message') in the parent to receive messages.
exec and execFile: The parent process receives the entire output of the child process as a string, with limited real-time interaction.
spawn: Provides streams for both stdin and stdout, allowing you to write data to the child process and read data from its output in real-time.
Common Use Cases:

Isolating Long-Running Tasks: Offload CPU-intensive tasks to child processes to prevent them from blocking the event loop of the main Node.js process, improving responsiveness.
Executing Shell Commands: Utilize exec or execFile to run shell commands and capture their output for further processing within your application.
Server-Side Scripting: Launch external scripts (e.g., Python scripts) using spawn and interact with their input and output streams to integrate them into your application's workflow.
Microservices Architecture: Break down your application logic into smaller, isolated child processes for improved modularity, scalability, and maintainability.
Benefits of Child Processes:

Improved Performance: By offloading tasks to child processes, you can prevent them from blocking the main process, leading to a more responsive application.
Enhanced Modularity: Structure your application code into smaller, isolated processes for better maintainability and reusability.
Leveraging External Tools: Extend your application's capabilities by utilizing external scripts or tools through child processes.
Things to Consider:

Resource Management: Be mindful of resource consumption when creating child processes, as they can utilize CPU, memory, and other system resources.
Communication Overhead: Communication between parent and child processes (especially with fork) can introduce some overhead compared to tasks executed within the main process.
Choosing the Right Method:

spawn: Ideal for scenarios requiring real-time interaction with the child process (e.g., writing data to its input or reading data from its output in chunks).
fork: Primarily used for creating worker processes in cluster environments due to its efficiency and ability to share the JavaScript environment with the parent process.
exec and execFile: Suitable for simple shell commands where you only need the complete output at once (e.g., checking the status of a system command).
Remember:

spawn provides the most flexibility for interacting with child processes.
fork is efficient for creating worker processes that share the JavaScript environment.
exec and execFile are best suited for simple shell commands with string output.

35. The Referer header
     is an optional HTTP header that identifies the address of the web page that linked to the current page.
    Purpose: Web servers can use this information to track how users navigate from one page to another on their website or across different websites

36. Express
    app = express(): Creates an Express application instance.
    get(), post(), put(), patch(), delete(), all(): Define routes for handling different HTTP methods (GET, POST, PUT, PATCH, DELETE) on specific paths.
    status(): Sets the HTTP status code of the response (e.g., 200 OK, 404 Not Found).
    send(): Sends a response message to the client (e.g., plain text, JSON data).
    sendFile(): Sends a static file (e.g., HTML, CSS, JavaScript) from the server to the client.
    express.urlencode(): Parses incoming form data encoded using the application/x-www-form-urlencoded format. Useful for handling form submissions.